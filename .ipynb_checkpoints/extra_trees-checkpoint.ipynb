{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Trees: Ensemble Methods - Extra Trees\n",
    "\n",
    "In Extra Trees, the features and splits are selected at random. All the data available in the training set is used to build each stump.\n",
    "\n",
    "*Since splits are chosen at random for each feature in the Extra Trees Classifier, itâ€™s less computationally expensive than a Random Forest. Extra Trees also show lower variance compared to Random Forests.*\n",
    "\n",
    "![Difference between Decision Trees, Random Forests and Extra Trees](./images/extratrees.png)\n",
    "\n",
    "The main difference between random forests and extra trees lies in the fact that, instead of computing the locally optimal feature/split combination (for the random forest), for each feature under consideration, a random value is selected for the split (for the extra trees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 1., 1.])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "\n",
    "X,y = load_iris(return_X_y=True)\n",
    "\n",
    "#train,test split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42)\n",
    "\n",
    "#ExtraTrees with gini\n",
    "etc = ExtraTreesClassifier(criterion='gini',max_depth=5,n_estimators=200)\n",
    "\n",
    "etc.fit(X_train,y_train)\n",
    "\n",
    "etc_predict = etc.predict(X_test)\n",
    "\n",
    "f1_score(y_test, etc_predict, average=None)"
   ]
  }
 ]
}